# Notes on Updating R Char Width Calculations

## Unicode

### Width Designations

From: https://www.unicode.org/reports/tr11/tr11-31.html

* F: East Asian Fullwidth: have a compatibility decomposition of type <wide>
  (WTF?) for characters that are otherwise implicitly narrow.
* H: East Asian Halfwidth: have a compatibility decomposition of type <narrow>,
  and the WON SIGN for characters that are otherwise implicitly wide..
* W: East Asian Wide: All other character that are always wide.
* Na: East Asian Narrow: All other characters that are always narrow
* A: Ambiguous: characters that might be narrow or wide and require additional
  information (e.g. Locale, as shown by `table_wcwidth`).
* N: Neutral, behave as narrow (not East Asian), although it seems that some of
  the so-labeled Neutral characters are actually better thought of as zero
  width, e.g. the 200B..200F range:

```
200B..200F;N     # Cf     [5] ZERO WIDTH SPACE..RIGHT-TO-LEFT MARK
```
This is discussed in tr11 section 6.2:

> In particular, nonspacing marks do not possess actual advance width.
> Therefore, even when displaying combining marks, the East_Asian_Width property
> cannot be related to the advance width of these characters.

The "decomposition type" thing is weird.  It seems to suggest that when
decomposed for compatibility, wide points to normally narrow characters to
display as wide (and vice versa).  No idea what this means.

> In a broad sense, wide characters include W, F, and A (when in East Asian
> context), and narrow characters include N, Na, H, and A (when not in East
> Asian context).

Note that 'A' characters are narrow in non-East-Asian contexts.  [Marcus
Kuhn](https://www.cl.cam.ac.uk/~mgk25/ucs/wcwidth.c) also resorts to narrow for
'A' characters because:

> width choice depends purely on a preference of backward compatibility with
> either historic CJK or Western practice.  Choosing single width for these
> characters is easy to justify as the appropriate long-term solution as the CJK
> practice of displaying these characters as double width comes from historic
> implementation simplicity and not any typographic considerations.

Recommendations:

> * Wide characters behave like ideographs in important ways, such as layout.
>   Except for certain punctuation characters, they are not rotated when
>   appearing in vertical text runs. In fixed-pitch fonts, they take up one Em
>   of space.
> * Halfwidth characters behave like ideographs in some ways,
>   however, they are rotated like narrow characters when appearing in vertical
>   text runs. In fixed-pitch fonts, they take up 1/2 Em of space.
> * Narrow characters behave like Western characters, for example, in line
>   breaking. They are rotated sideways, when appearing in vertical text. In
>   fixed-pitch East Asian fonts, they take up 1/2 Em of space, but in
>   rendering, a non-East Asian, proportional font is often substituted.
> * Ambiguous characters behave like wide or narrow characters depending on the
>   context (language tag, script identification, associated font, source of
>   data, or explicit markup; all can provide the context). If the context
>   cannot be established reliably, they should be treated as narrow characters
>   by default [OPPOSITE OF r-utf8].
> * Emoji style standardized variation sequences behave as though they were East
>   Asian Wide, regardless of their assigned East_Asian_Width property value.

What about Zero Width?  They don't appear specifically in the table, and many of
the known zero width controls are just "N".

> All private-use characters are by default classified as Ambiguous, because
> their definition depends on context.

> Unassigned code points in ranges intended for CJK ideographs are classified as
> Wide. Those ranges are: [NOTE: THIS ARE IN THE TABLES, AT LEAST SOME OF THEM]
>
> * the CJK Unified Ideographs block, 4E00..9FFF
> * the CJK Unified Ideographs Externsion A block, 3400..4DBF
> * the CJK Compatibility Ideographs block, F900..FAFF
> * the Supplementary Ideographic Plane, 20000..2FFFF
> * the Tertiary Ideographic Plane, 30000..3FFFF
>
> All other unassigned code points are by default classified as Neutral.

One interesting implication of all this is what the width for code points 1FA96
and greater but less that 20000 is not specified in 12.1?

As noted earlier there are a bunch of characters that R designates as East Asian
Ambiguous that have different widths in different locales.

There is additional complexity with emoji.  `ut8` will treat all emoji as being
wide, but at least based on my terminal it should be the `emoji_presentation`
emojis that show up as wide.  For example Sun:

```{r}
writeLines(c('\u260034\n1234'))
writeLines(c('\u2600\uFE0F34\n1234'))  # force emoji presentation
```

Should be treated as narrow, whereas sparkles as wide:

```{r}
writeLines(c('\u272834\n1234'))
```

Yet `utf8` treats both as wide:

```{r}
utf8::utf8_width(c('\u2600', '\u2728'))
```
```
[1] 2 2
```

The East Asian Text actually reports this sensibly, Neutral for Sun and Wide for
sparkles.  It's a bit complicated b/c it seems browsers aren't always consistent
with monospace font on the display width of the glyphs.  In Rstudio
the non-emoji sun glyph is a little wider than 1, and the emoji one is exactly
two.  In firefox neither is width two.

So for a half-assed attempt at updating R we could go with the table
designation.

### Zero Widths

Need to determine the categories that are zero width:

* Controls
* Non Characters (ending in FFFE or FFFF and FDD0..FDEF)
* Combining characters
    * Spacing (Mc) vs non-spacing (Mn), (an Me for enclosing mark)
    * Diacritics (combining diacritics), "principal class of nonspacing
      combining characters", sometimes known as "marks"?
    * Base character determines positioning, but not necessarily width
    * Have a canonical combining class (though some that don't are still
      combining)
    * Note that ^\p{ccc=0} (property cannonical combined class != 0) is not
      quite equivalent to \p{gc=Mn} (general class non-spacing mark)
* Default Ignorable Code Point:
    * Includes things like U+FE0F that should not be rendered at all if the
      implementation does not support them (as opposed to trying to render a
      stand-in glyph).
* Zero-width enclosing (e.g. a sign frame around a symbol) (general category
  Me?)
* Surrogates?

Marcus Kuhn uses:

```
/* sorted list of non-overlapping intervals of non-spacing characters */
/* generated by "uniset +cat=Me +cat=Mn +cat=Cf -00AD +1160-11FF +200B c" */
```

U+00AD is softhyphen, U+1160..11FF are Hangul Jongseong, U+200B is zero width
space (but it's in Cf??).

Rlocale adds \p{gc=Cc}.

## ICU

External library that is optionally linked (?) to R.  More details in
`?icuSetCollate`.  GÃ¡bor was curious if we could use functions therein for width
calculations.  Given:

> Optionally, R can be built to collate character strings by ICU
> (http://site.icu-project.org). For such systems, icuSetCollate can be used to
> tune the way collation is done. On other builds calling this function does
> nothing, with a warning.

Sounds like ICU is used by default except on windows.

> ICU is used by default wherever it is available: this include macOS, Solaris
> and many Linux installations. As it works internally in UTF-8, it will be most
> efficient in UTF-8 locales.

It appears ICU is only used for locale.

TODO: find out if there are appropriate entry points to replace `Ri18n_wcswidth`

Probably we want `BreakIterator` as it "count graphemes (or characters)", or
maybe `CharacterIterator`, but both of these are probably C++?  Actually
this stuff is supposedly available in `utf.h`.  `BreakIterator` seems to be
where it's at, although we still need to figure the overall width of the
grapheme, probably from the EAW of the first element combined with the other
character attributes?  So we need to track down the function that provides the
character attributes in addition the EAW (i.e. 'emoji_presentation' chars are
wide, even if not so EAW, also wide if made emoji presentation bu uFE0F).

## Width Calculations

### Overview

Actual width calculations are done by `R_nchar` in "src/main/character.c".
There are three pathways to the "Width" calculation:

1. String is UTF-8
2. else we are in a `mbslocale`
3. else `strlen(translateChar(string))`

For the first two the general logic seems to be to convert to UCS (a.k.a.
unicode for all intents and purposes) and store that as an `Rwchar_t` to look up
in the `table_wcwidth` table.  `Rwchar_t` is a wrapper for `wchar_t` that
switches to `int` in windows that still uses the 16-bit LE encoding.  It is
unclear whether R actually checks the size of `wchar_t` as per wikipedia it may
be insufficient not just on windows:

> The width of wchar_t is compiler-specific and can be as small as 8 bits.
> Consequently, programs that need to be portable across any C or C++ compiler
> should not use wchar_t for storing Unicode text. The wchar_t type is intended
> for storing compiler-defined wide characters, which may be Unicode characters
> in some compilers.

The last one just seems to be the byte length of the string the current locale,
which presumably is not a multi-byte locale so is just the number of characters
in the string.

In order to add the multi code point characters we'll need to update
`Ri18n_wcswidth` to account for it, and switch the UTF-8 loop to use that as
currently the UTF-8 loop just computes the width one-by-one.  It may be possible
to use an ICU function to do this.

More details follow.

### UTF-8 Width

```{c}
wchar_t wc1;
Rwchar_t ucs;
int nc = 0;
// Advance by the computed utf8 width
// utf8clen uses a lookup table to compute
// width, allows >4, but validity is
// checked first
for( ; *p; p += utf8clen(*p)) {
    // Convert to Unicode Code Point, high
    // surrogate business is for sizeof(wchar_t)
    // == 16 as in Windoze.  See main/utils.c
    utf8toucs(&wc1, p);
    if (IS_HIGH_SURROGATE(wc1))
        ucs = utf8toucs32(wc1, p);
    else
        ucs = wc1;
    // Actually compute width
    // See main/rlocale.c
    nc += Ri18n_wcwidth(ucs);
}
return nc;
```

NOTE: UCS is Universal Coded Character Set, which is supposed to be:

> This ISO/IEC 10646 standard is maintained in conjunction with The Unicode
> Standard ("Unicode"), and they are code-for-code identical.

Here is the width from "main/rlocale.c".  Changing logic to allow multi-element
emoji will require a bit of surgery, probably to `R_nchar`.

Question: what is the i18 business (appears related to ICU).

```
int Ri18n_wcwidth(Rwchar_t c)
{
    char lc_str[128];
    unsigned int i, j;

    static char *lc_cache = "";
    static int lc = 0;

    if (0 != strcmp(setlocale(LC_CTYPE, NULL), lc_cache)) {
      // ... set locale if not set ...
      // Importantly generates the `lc` offset for the lookup table column,
      // based on comments in rlocale.h this is important b/c some locales have
      // different conceptions of character width, paricularly in East-Asian
      // ambiguous category.
    }
    // Attempt to lookup in table_wcwidth in main/rlocal_data.h,
    // a `static const struct interval_wcwidth` that contains:
    // where CP is unicode code point in hex:
    // {
    //   {start CP, end CP, per_locale_widths[7]},
    //   {... repeat above for each range}
    // }
    // wcwidthsearch does a binary search in the presumably sorted
    // table_wcwidth.

    int wd = wcwidthsearch(c, table_wcwidth,
			   (sizeof(table_wcwidth)/sizeof(struct interval_wcwidth)),
			   lc);

    if (wd >= 0) return wd; // currently all are 1 or 2.

    // Search for zero width characters

    int zw = wcsearch(c, zero_width, zero_width_count);
    return zw ? 0 : 1; // assume unknown chars are width one.
}
```

We need to better understand the locale width exceptions in EA ambiguous, and
under what circumstances the `lc` value / how it is changed.  Maybe we can just
compute the table and not worry about it.

### MBCS locale width

Still all from "main/character.c:R_nchar":

```{c}
// Convert to native encoding, presumably so we can use mbstowcs, which
// is a C99 function?  mbstowcs also returns how many wide chars there
// are, so the first use is just for size

const char *xi = translateChar(string);
int nc = (int) mbstowcs(NULL, xi, 0);
if (nc >= 0) {
    const void *vmax = vmaxget();
    wchar_t *wc = (wchar_t *)
        R_AllocStringBuffer((nc+1)*sizeof(wchar_t), &cbuff);

    // Now convert into our buffer.  Note for windows
    // R defines Rmbstowcs in gnuwin32/extra.c

    mbstowcs(wc, xi, nc + 1);

    // Compute width as before

    int nci18n = Ri18n_wcswidth(wc, 2147483647);
    vmaxset(vmax);
    return (nci18n < 1) ? nc : nci18n;
} else if (allowNA)
    error(_("invalid multibyte string, %s"), msg_name);
else
    return NA_INTEGER;
```

